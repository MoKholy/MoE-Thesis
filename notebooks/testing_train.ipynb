{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from scripts.losses import *\n",
    "from scripts.models import *\n",
    "import numpy as np\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from tensorboardX import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 100\n",
    "num_samples = 1\n",
    "num_experts = 3\n",
    "num_classes = 3\n",
    "hidden_dim = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# create dummy data\n",
    "X = torch.randn(num_samples, input_dim)\n",
    "\n",
    "# create dummy targets\n",
    "y = torch.randint(0, num_classes, (num_samples,))\n",
    "\n",
    "# create one hot encoding for targets\n",
    "y_onehot = F.one_hot(y, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y: tensor([0])\n",
      "y shape: torch.Size([1])\n",
      "y_onehot: tensor([[1, 0, 0]])\n",
      "y_onehot shape: torch.Size([1, 3])\n"
     ]
    }
   ],
   "source": [
    "print(f\"y: {y}\")\n",
    "print(f\"y shape: {y.shape}\")\n",
    "print(f\"y_onehot: {y_onehot}\")\n",
    "print(f\"y_onehot shape: {y_onehot.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gating_loss = MSEGatingLoss()\n",
    "expert_loss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dummy model\n",
    "model = MixtureOfExperts(input_dim=input_dim, hidden_dim=hidden_dim, num_classes=num_classes, num_experts=num_experts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X type: torch.float32\n",
      "y type: torch.int64\n",
      "y_onehot type: torch.int64\n"
     ]
    }
   ],
   "source": [
    "# print types of each data\n",
    "print(f\"X type: {X.dtype}\")\n",
    "print(f\"y type: {y.dtype}\")\n",
    "print(f\"y_onehot type: {y_onehot.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mixture_out shape: torch.Size([1, 3]) -- y_shape: torch.Size([1])\n",
      "gating_out shape: torch.Size([1, 3]) -- y_onehot_shape: torch.Size([1, 3])\n",
      "\n",
      "output: (tensor([[-0.0677,  0.0445, -0.0869]], grad_fn=<SumBackward1>), tensor([[0.2225, 0.1577, 0.6198]], grad_fn=<SoftmaxBackward0>), tensor([[[-0.2744,  0.0323,  0.0809],\n",
      "         [-0.0555,  0.2614, -0.3917],\n",
      "         [ 0.0034, -0.0063, -0.0696]]], grad_fn=<StackBackward0>))\n"
     ]
    }
   ],
   "source": [
    "# get output from model\n",
    "output = model(X)\n",
    "\n",
    "\n",
    "mixture_out, gating_out, expert_out = output\n",
    "\n",
    "\n",
    "# print shapes of each output\n",
    "print(f\"mixture_out shape: {mixture_out.shape} -- y_shape: {y.shape}\")\n",
    "print(f\"gating_out shape: {gating_out.shape} -- y_onehot_shape: {y_onehot.shape}\")\n",
    "print(f\"\")\n",
    "\n",
    "# get gating loss\n",
    "g_loss = gating_loss(gating_out, y_onehot.float())\n",
    "\n",
    "# get expert loss\n",
    "e_loss = expert_loss(mixture_out, y)\n",
    "\n",
    "# get total loss\n",
    "total_loss = g_loss + e_loss\n",
    "\n",
    "print(f\"output: {output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_loss.dtype: torch.float32\n"
     ]
    }
   ],
   "source": [
    "print(f\"total_loss.dtype: {total_loss.dtype}\")\n",
    "\n",
    "# total_loss = total_loss.float()\n",
    "total_loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter()\n",
    "# test writer dummy data\n",
    "writer.add_scalar(\"test\", 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs: 100%|██████████| 1/1 [00:00<00:00, 44.43it/s]\n"
     ]
    }
   ],
   "source": [
    "epochs = 1 \n",
    "batch_size = 1\n",
    "lr = 0.001\n",
    "# track best f1_score\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.1)\n",
    "\n",
    "gating_loss = MSEGatingLoss()\n",
    "expert_loss = nn.CrossEntropyLoss()\n",
    "\n",
    "# create dummy dataloader\n",
    "dataloader = DataLoader(dataset=list(zip(X, y_onehot, y)), batch_size=batch_size, shuffle=True)\n",
    "dataloader_val = DataLoader(dataset=list(zip(X, y_onehot, y)), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "best_f1_score = 0.0\n",
    "writer = SummaryWriter()\n",
    "model.to(device)\n",
    "for epoch in tqdm(range(epochs), desc=\"Epochs\"):\n",
    "\n",
    "    \n",
    "    # set model to train\n",
    "    model.train()\n",
    "\n",
    "    # track losses, predictions and labels\n",
    "    total_expert_loss = 0.0\n",
    "    total_gating_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    # loop over data from dataloader\n",
    "\n",
    "    for input, true_gating_labels, labels in tqdm(dataloader, desc=\"Batches\", leave=False):\n",
    "        # get data to device\n",
    "        input = input.to(device)\n",
    "        true_gating_labels = true_gating_labels.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # get output from model\n",
    "        mixture_out, gating_out, expert_out = model(input)\n",
    "        \n",
    "        # expert out for debugging\n",
    "\n",
    "        # get gating loss\n",
    "        gate_loss = gating_loss(gating_out, true_gating_labels.float())\n",
    "        total_gating_loss += gate_loss.item()\n",
    "        # get expert loss\n",
    "        exprt_loss = expert_loss(mixture_out, labels)\n",
    "        total_expert_loss += exprt_loss.item()\n",
    "        # get total loss\n",
    "        total_loss = gate_loss + exprt_loss\n",
    "        # zero gradients\n",
    "        optimizer.zero_grad()\n",
    "        # backpropagate\n",
    "        total_loss.backward()\n",
    "        # update weights\n",
    "        optimizer.step()\n",
    "        # update scheduler\n",
    "        scheduler.step()\n",
    "\n",
    "        # calculate predictions for accuracy and F1 score\n",
    "        _, preds = torch.max(mixture_out, dim=1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # calculate average losses for epoch\n",
    "    avg_expert_loss = total_expert_loss / len(dataloader)\n",
    "    avg_gating_loss = total_gating_loss / len(dataloader)\n",
    "\n",
    "    # calculate accuracy and F1 score\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds, average=\"macro\")\n",
    "\n",
    "    # write to tensorboard\n",
    "    writer.add_scalar(\"Train/Avg_Train_Expert_Loss\", avg_expert_loss, epoch)\n",
    "    writer.add_scalar(\"Train/Avg_Train_Gating_Loss\", avg_gating_loss, epoch)\n",
    "    writer.add_scalar(\"Train/Train_Accuracy\", accuracy, epoch)\n",
    "    writer.add_scalar(\"Train/Train_F1_Score\", f1, epoch)\n",
    "\n",
    "    # perform validation\n",
    "\n",
    "    # set model to eval\n",
    "    model.eval()\n",
    "\n",
    "    # track losses, predictions and labels for validation\n",
    "    total_expert_loss_val = 0.0\n",
    "    total_gating_loss_val = 0.0\n",
    "    all_preds_val = []\n",
    "    all_labels_val = []\n",
    "\n",
    "    # loop over data from dataloader\n",
    "    for input, true_gating_labels, labels in tqdm(dataloader_val, desc=\"Validation\", leave=False):\n",
    "        # get data to device\n",
    "        input = input.to(device)\n",
    "        true_gating_labels = true_gating_labels.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # get output from model\n",
    "        mixture_out, gating_out, expert_out = model(input)\n",
    "        # get gating loss\n",
    "        gate_loss = gating_loss(gating_out, true_gating_labels.float())\n",
    "        total_gating_loss_val += gate_loss.item()\n",
    "        # get expert loss\n",
    "        exprt_loss = expert_loss(mixture_out, labels)\n",
    "        total_expert_loss_val += exprt_loss.item()\n",
    "\n",
    "        # calculate predictions for accuracy and F1 score\n",
    "        _, preds = torch.max(mixture_out, dim=1)\n",
    "        all_preds_val.extend(preds.cpu().numpy())\n",
    "        all_labels_val.extend(labels.cpu().numpy())\n",
    "\n",
    "    # calculate average losses for epoch\n",
    "    avg_expert_loss_val = total_expert_loss_val / len(dataloader_val)\n",
    "    avg_gating_loss_val = total_gating_loss_val / len(dataloader_val)\n",
    "\n",
    "    # calculate accuracy and F1 score\n",
    "    accuracy_val = accuracy_score(all_labels_val, all_preds_val)\n",
    "    f1_val = f1_score(all_labels_val, all_preds_val, average=\"macro\")\n",
    "\n",
    "    # write to tensorboard\n",
    "    writer.add_scalar(\"Train/Avg_Val_Expert_Loss\", avg_expert_loss_val, epoch)\n",
    "    writer.add_scalar(\"Train/Avg_Val_Gating_Loss\", avg_gating_loss_val, epoch)\n",
    "    writer.add_scalar(\"Train/Val_Accuracy\", accuracy_val, epoch)\n",
    "    writer.add_scalar(\"Train/Val_F1_Score\", f1_val, epoch)\n",
    "\n",
    "    # check if F1 score is best\n",
    "    if f1_val > best_f1_score:\n",
    "        # save model\n",
    "        torch.save(model.state_dict(), \"best_model.pt\")\n",
    "        # update best F1 score\n",
    "        best_f1_score = f1\n",
    "    \n",
    "writer.close()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
