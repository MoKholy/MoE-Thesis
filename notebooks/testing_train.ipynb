{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from scripts.losses import *\n",
    "from scripts.models import *\n",
    "import numpy as np\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from tensorboardX import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 100\n",
    "num_samples = 1\n",
    "num_experts = 3\n",
    "num_classes = 3\n",
    "hidden_dim = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# create dummy data\n",
    "X = torch.randn(num_samples, input_dim)\n",
    "\n",
    "# create dummy targets\n",
    "y = torch.randint(0, num_classes, (num_samples,))\n",
    "\n",
    "# create one hot encoding for targets\n",
    "y_onehot = F.one_hot(y, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y: tensor([2])\n",
      "y shape: torch.Size([1])\n",
      "y_onehot: tensor([[0, 0, 1]])\n",
      "y_onehot shape: torch.Size([1, 3])\n"
     ]
    }
   ],
   "source": [
    "print(f\"y: {y}\")\n",
    "print(f\"y shape: {y.shape}\")\n",
    "print(f\"y_onehot: {y_onehot}\")\n",
    "print(f\"y_onehot shape: {y_onehot.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get device\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "gating_loss = MSEGatingLoss()\n",
    "expert_loss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dummy model\n",
    "model = MixtureOfExperts(input_dim=input_dim, hidden_dim=hidden_dim, num_classes=num_classes, num_experts=num_experts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X type: torch.float32\n",
      "y type: torch.int64\n",
      "y_onehot type: torch.int64\n"
     ]
    }
   ],
   "source": [
    "# print types of each data\n",
    "print(f\"X type: {X.dtype}\")\n",
    "print(f\"y type: {y.dtype}\")\n",
    "print(f\"y_onehot type: {y_onehot.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expert_outputs_shape: torch.Size([1, 3, 3])\n",
      "gating_weights_shape: torch.Size([1, 3])\n",
      "mixture_output_shape: torch.Size([1, 3])\n",
      "mixture_out shape: torch.Size([1, 3]) -- y_shape: torch.Size([1])\n",
      "gating_out shape: torch.Size([1, 3]) -- y_onehot_shape: torch.Size([1, 3])\n",
      "\n",
      "output: (tensor([[ 0.2149, -0.0186, -0.2226]], grad_fn=<SumBackward1>), tensor([[0.3642, 0.4012, 0.2346]], grad_fn=<SoftmaxBackward0>), tensor([[[ 0.1415, -0.3374, -0.2104],\n",
      "         [ 0.3098,  0.4765, -0.2298],\n",
      "         [ 0.1663, -0.3705, -0.2293]]], grad_fn=<StackBackward0>))\n"
     ]
    }
   ],
   "source": [
    "# get output from model\n",
    "output = model(X)\n",
    "\n",
    "\n",
    "mixture_out, gating_out, expert_out = output\n",
    "\n",
    "\n",
    "# print shapes of each output\n",
    "print(f\"mixture_out shape: {mixture_out.shape} -- y_shape: {y.shape}\")\n",
    "print(f\"gating_out shape: {gating_out.shape} -- y_onehot_shape: {y_onehot.shape}\")\n",
    "print(f\"\")\n",
    "\n",
    "# get gating loss\n",
    "g_loss = gating_loss(gating_out, y_onehot.float())\n",
    "\n",
    "# get expert loss\n",
    "e_loss = expert_loss(mixture_out, y)\n",
    "\n",
    "# get total loss\n",
    "total_loss = g_loss + e_loss\n",
    "\n",
    "print(f\"output: {output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_loss.dtype: torch.float32\n"
     ]
    }
   ],
   "source": [
    "print(f\"total_loss.dtype: {total_loss.dtype}\")\n",
    "\n",
    "# total_loss = total_loss.float()\n",
    "total_loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter()\n",
    "# test writer dummy data\n",
    "writer.add_scalar(\"test\", 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1 \n",
    "batch_size = 1\n",
    "lr = 0.001\n",
    "\n",
    "for epoch in tqdm(range(epochs), desc=\"Epochs\"):\n",
    "    # set model to train\n",
    "    model.train()\n",
    "\n",
    "    # track losses, predictions and labels\n",
    "    total_expert_loss = 0.0\n",
    "    total_gating_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    # loop over data from dataloader\n",
    "\n",
    "    for input, true_gating_labels, labels in tqdm(dataloader, desc=\"Batches\", leave=False):\n",
    "        # get data to device\n",
    "        input = input.to(device)\n",
    "        true_gating_labels = true_gating_labels.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # get output from model\n",
    "        mixture_out, gating_out, expert_out = model(input)\n",
    "        \n",
    "        # expert out for debugging\n",
    "\n",
    "        # get gating loss\n",
    "        gating_loss = gating_loss(gating_out, true_gating_labels.float())\n",
    "\n",
    "        # get expert loss\n",
    "        expert_loss = expert_loss(mixture_out, labels)\n",
    "\n",
    "        # get total loss\n",
    "        total_loss = gating_loss + expert_loss\n",
    "\n",
    "        # zero gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # backpropagate\n",
    "        total_loss.backward()\n",
    "\n",
    "        # update weights\n",
    "        optimizer.step()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
